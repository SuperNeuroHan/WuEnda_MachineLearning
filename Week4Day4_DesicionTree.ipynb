{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tjb1OjLblJnx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from public_tests import *\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "Suppose you are starting a company that grows and sells wild mushrooms.\n",
        "\n",
        "*   Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes.\n",
        "\n",
        "*   You have some existing data that you can use for this task.\n",
        "\n",
        "Can you use the data to help you identify which mushrooms can be sold safely?"
      ],
      "metadata": {
        "id": "ZAvQWmZ3rJ4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
        "y_train = np.array([1,1,0,0,1,0,0,1,1,0])\n",
        "root_indices = np.arange(len(X_train))\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu4PQEdgrVb0",
        "outputId": "22937adc-c504-4fc7-f776-02eeed6940ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 3), (10,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `X_train` contains three features for each example\n",
        "    - Brown Color (A value of `1` indicates \"Brown\" cap color and `0` indicates \"Red\" cap color)\n",
        "    - Tapering Shape (A value of `1` indicates \"Tapering Stalk Shape\" and `0` indicates \"Enlarging\" stalk shape)\n",
        "    - Solitary  (A value of `1` indicates \"Yes\" and `0` indicates \"No\")\n",
        "\n",
        "- `y_train` is whether the mushroom is edible\n",
        "    - `y = 1` indicates edible\n",
        "    - `y = 0` indicates poisonous"
      ],
      "metadata": {
        "id": "hEVY5k3At6is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ex01\"></a>\n",
        "### Exercise 1\n",
        "\n",
        "Please complete the `compute_entropy()` function using the previous instructions."
      ],
      "metadata": {
        "id": "Lj2JvoUntbM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The log is calculated with base  2\n",
        "# For implementation purposes,  0log2(0)=0 . That is, if p_1 = 0 or p_1 = 1, set the entropy to 0\n",
        "# Make sure to check that the data at a node is not empty (i.e. len(y) != 0). Return 0 if it is\n",
        "\n",
        "def compute_entropy(y):\n",
        "  if len(y) ==0:\n",
        "    return 0\n",
        "  else:\n",
        "    num_edible = np.count_nonzero(y == 1)\n",
        "    p = num_edible / len(y)\n",
        "    if p == 0 or p ==1:\n",
        "      return 0\n",
        "    else:\n",
        "      return -p * np.log2(p) - (1 - p) * np.log2(1 - p)"
      ],
      "metadata": {
        "id": "Vw45gxNhtcmI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ex02\"></a>\n",
        "### Exercise 2\n",
        "\n",
        "Please complete the `split_dataset()` function shown below\n",
        "\n",
        "- For each index in `node_indices`\n",
        "    - If the value of `X` at that index for that feature is `1`, add the index to `left_indices`\n",
        "    - If the value of `X` at that index for that feature is `0`, add the index to `right_indices`"
      ],
      "metadata": {
        "id": "rK3cQ1l4v12E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, node_indices, feature):\n",
        "  left_indices = []\n",
        "  right_indices = []\n",
        "  for i in node_indices:\n",
        "    if X[i,feature] == 1:\n",
        "      left_indices.append(i)\n",
        "    else:\n",
        "      right_indices.append(i)\n",
        "  return left_indices, right_indices"
      ],
      "metadata": {
        "id": "uYebilV1vmTQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ex03\"></a>\n",
        "### Exercise 3\n",
        "\n",
        "Please complete the `compute_information_gain()` function shown below to compute\n",
        "\n",
        "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
        "\n",
        "where\n",
        "- $H(p_1^\\text{node})$ is entropy at the node\n",
        "- $H(p_1^\\text{left})$ and $H(p_1^\\text{right})$ are the entropies at the left and the right branches resulting from the split\n",
        "- $w^{\\text{left}}$ and $w^{\\text{right}}$ are the proportion of examples at the left and right branch respectively\n",
        "\n",
        "Note:\n",
        "- You can use the `compute_entropy()` function that you implemented above to calculate the entropy\n",
        "- We've provided some starter code that uses the `split_dataset()` function you implemented above to split the dataset"
      ],
      "metadata": {
        "id": "MAXeM5DFzXIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_information_gain(X,y,node_indices, feature):\n",
        "  left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
        "\n",
        "  w_left = len(left_indices) / len(node_indices)\n",
        "  w_right = len(right_indices) / len(node_indices)\n",
        "\n",
        "  H_left = compute_entropy(y[left_indices])\n",
        "  H_right = compute_entropy(y[right_indices])\n",
        "  H_node = compute_entropy(y[node_indices])\n",
        "\n",
        "  information_gian = H_node - (w_left * H_left + w_right * H_right)\n",
        "  return information_gian"
      ],
      "metadata": {
        "id": "KH_LA62TzXtB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature 0: Brown Color (A value of 1 indicates \"Brown\" cap color and 0 indicates \"Red\" cap color)\n",
        "Browncolor_information_gain = compute_information_gain(X_train, y_train, root_indices,0)\n",
        "print(f\"Information Gain for Brown Color: {Browncolor_information_gain}\")\n",
        "\n",
        "# feature 1: Tapering Shape (A value of 1 indicates \"Tapering Stalk Shape\" and 0 indicates \"Enlarging\" stalk shape)\n",
        "Taperingshape_information_gain = compute_information_gain(X_train, y_train,root_indices, 1)\n",
        "print(f\"Information Gain for Tapering Shape: {Taperingshape_information_gain}\")\n",
        "\n",
        "# feature 2: Solitary (A value of 1 indicates \"Yes\" and 0 indicates \"No\") -- maximum information gain\n",
        "Solitary_information_gain = compute_information_gain(X_train, y_train,root_indices, 2)\n",
        "print(f\"Information Gain for Solitary: {Solitary_information_gain}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CG9CVUO1ENs",
        "outputId": "8cf95a5e-ffc6-4f96-b6b6-9159cdb662fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain for Brown Color: 0.034851554559677034\n",
            "Information Gain for Tapering Shape: 0.12451124978365313\n",
            "Information Gain for Solitary: 0.2780719051126377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ex04\"></a>\n",
        "### Exercise 4\n",
        "Please complete the `get_best_split()` function shown below.\n",
        "- The function takes in the training data, along with the indices of datapoint at that node\n",
        "- The output of the function the feature that gives the maximum information gain\n",
        "    - You can use the `compute_information_gain()` function to iterate through the features and calculate the information for each feature"
      ],
      "metadata": {
        "id": "s5Qphscs2nV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(X, y, node_indices):\n",
        "  best_features = -1\n",
        "  max_information_gain = 0\n",
        "  feature = X.shape[1]\n",
        "\n",
        "  for i in range(feature):\n",
        "    information_gain = compute_information_gain(X,y,node_indices, i)\n",
        "    if max_information_gain < information_gain:\n",
        "      best_features = i\n",
        "      max_information_gain = information_gain\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  return best_features"
      ],
      "metadata": {
        "id": "jBHE-gmQ2m85"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_feature = get_best_split(X_train, y_train, root_indices)\n",
        "print(f\"Best Feature: {best_feature}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T7yeZHv6OTW",
        "outputId": "42e4cc7d-18d2-4a0a-de58-84df187faffe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Feature: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5\"></a>\n",
        "## Building the tree\n",
        "\n",
        "In this section, we use the functions you implemented above to generate a decision tree by successively picking the best feature to split on until we reach the stopping criteria (maximum depth is 2)."
      ],
      "metadata": {
        "id": "rVj8qHvI6oeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not graded\n",
        "tree = []\n",
        "\n",
        "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
        "    \"\"\"\n",
        "    Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node.\n",
        "    This function just prints the tree.\n",
        "\n",
        "    Args:\n",
        "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
        "        y (array like):         list or ndarray with n_samples containing the target variable\n",
        "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
        "        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right']\n",
        "        max_depth (int):        Max depth of the resulting tree.\n",
        "        current_depth (int):    Current depth. Parameter used during recursive call.\n",
        "\n",
        "    \"\"\"\n",
        "    if current_depth == max_depth:\n",
        "      formatting = ''* current_depth + '-'* current_depth\n",
        "      print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
        "      return\n",
        "\n",
        "    best_feature = get_best_split(X,y,node_indices)\n",
        "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
        "    tree.append((current_depth, branch_name, best_feature, node_indices))\n",
        "    formatting = \"-\"*current_depth\n",
        "    print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
        "\n",
        "    build_tree_recursive(X, y, left_indices, 'Left', max_depth, current_depth + 1)\n",
        "    build_tree_recursive(X, y, right_indices, 'Right', max_depth, current_depth + 1)\n"
      ],
      "metadata": {
        "id": "SxwHpOc36qf1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE0HQ_2OAoTf",
        "outputId": "d67deb66-1c8f-4a5f-eaf0-125316af64ed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Depth 0, Root: Split on feature: 2\n",
            "- Depth 1, Left: Split on feature: 0\n",
            "-- Left leaf node with indices [0, 1, 4, 7]\n",
            "-- Right leaf node with indices [5]\n",
            "- Depth 1, Right: Split on feature: 1\n",
            "-- Left leaf node with indices [8]\n",
            "-- Right leaf node with indices [2, 3, 6, 9]\n"
          ]
        }
      ]
    }
  ]
}